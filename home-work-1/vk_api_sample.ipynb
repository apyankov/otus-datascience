{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vk_api\n",
    "import io\n",
    "import json, codecs\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Загружаем данные из vk_api, сохраняем на диск\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credentials: нужно указать логин/пароль к vk.com\n",
    "# чтобы случайно не закомитить версию с логин/пароль - выносим эти данные в отдельный файл, который исключаем в .gitignore\n",
    "credentialsFileName = \"vk_login_password.txt\" # формат файла: 1-я строка = логин, 2-я строка = пароль\n",
    "# затираем значения, которые могли сохраниться с прошлых запусков (в notebook)\n",
    "login = '+71231234567' \n",
    "password = ''\n",
    "\n",
    "# загружаем значения из файла\n",
    "try:\n",
    "    loginFile = open(credentialsFileName, 'r')\n",
    "    login = loginFile.readline().strip() # в формате: '+71231234567'\n",
    "    password = loginFile.readline().strip()\n",
    "except IOError:\n",
    "    print (\"No file with login/password: создайте файл \" + credentialsFileName + \", в котором 1-я строка = логин, 2-я строка = пароль\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# используем:\n",
    "#  wrapper-lib vk_api: https://github.com/python273/vk_api\n",
    "#  описание Api от vk: https://vk.com/dev/groups.search?params[q]=bitcoin&params[future]=0&params[market]=0&params[offset]=3&params[count]=3&params[v]=5.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# параметры запуска\n",
    "GROUP_KEYWORD = 'bitcoin' # интересуют сообщества, в названии которых есть такое слово\n",
    "COUNT_GROUPS = 50 # обработаем столько сообществ\n",
    "COUNT_MESSAGES_PER_GROUP = 100 # в каждом сообществе, со стены возьмем столько сообщений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем соединение, api\n",
    "vk_session = vk_api.VkApi(login, password)\n",
    "vk_session.auth(token_only=True)\n",
    "api = vk_session.get_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# константы и правила, которые используем при работе с файлами\n",
    "FOLDER_PREFIX = './files/' # folder, в которую складываем файлы\n",
    "FILE_EXTENSION = '.txt' # расширение для json-файлов\n",
    "\n",
    "def fileNameFunc(rawFileName):\n",
    "    return FOLDER_PREFIX + rawFileName + FILE_EXTENSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данные по сообществам - получаем по http\n",
    "def obtainGroups(api, keyword, count):\n",
    "    print(\"obtainGroups, keyword=\" + keyword + \", count=\" + str(count))\n",
    "    results = api.groups.search(q=keyword, count=count)\n",
    "    return results['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получить N записей со стены сообщества/пользователя\n",
    "def obtainWallItems(api, owner_id, count):\n",
    "    # protection: проверяем входные значения\n",
    "    if(count > 100): # todo: можно приделать scroll, то есть, разбить запрос на несколько, в каждом count не более 100\n",
    "        raise AssertionError(\"count должен быть <= 100, но передали:\" + str(count))\n",
    "\n",
    "    # основная часть\n",
    "    results = api.wall.get(owner_id=owner_id, filter = 'owner', count = count, offset=0)\n",
    "    print(\"obtainWallItems, owner_id=\" + str(owner_id) + \", retrieve \" + str(len(results['items'])) + \", of total \" + str(results['count']))\n",
    "    return results['items']\n",
    "\n",
    "# для напоминания - сохраним в комментариях альтернативный метод vk_api для получения сообщений со стены сообщества\n",
    "#tools = vk_api.VkTools(vk_session)\n",
    "#wall = tools.get_all('wall.get', 10, {'owner_id': -92718200, 'filter':'owner'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# записываем json в файл\n",
    "def writeJsonToFile(fileName, jsonData):\n",
    "    with io.open(fileName, 'w', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(jsonData, ensure_ascii=False, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obtainGroups, keyword=bitcoin, count=50\n"
     ]
    }
   ],
   "source": [
    "# получаем все интересующие сообщества, записываем в файл\n",
    "groups = obtainGroups(api, 'bitcoin', COUNT_GROUPS)\n",
    "writeJsonToFile(fileNameFunc('groups'), groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip group:16269693\n",
      "skip group:16219861\n",
      "total groups для обработки: 48\n"
     ]
    }
   ],
   "source": [
    "# отфильтруем сообщества - нам нужны только те, у которых есть доступ к сообщениям на стене\n",
    "group_ids = []\n",
    "for group in groups:\n",
    "    if(group['is_closed'] == 0):\n",
    "        group_ids.append(group['id'])\n",
    "    else:\n",
    "        print('skip group:' + str(group['id']))\n",
    "print('total groups для обработки: ' + str(len(group_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obtainWallItems, owner_id=-46371384retrieve 100, of total 48228\n",
      "obtainWallItems, owner_id=-92718200retrieve 100, of total 10601\n",
      "obtainWallItems, owner_id=-632045retrieve 100, of total 28475\n",
      "obtainWallItems, owner_id=-93604475retrieve 100, of total 14366\n",
      "obtainWallItems, owner_id=-59454515retrieve 100, of total 31644\n",
      "obtainWallItems, owner_id=-79363873retrieve 100, of total 830\n",
      "obtainWallItems, owner_id=-51789870retrieve 100, of total 13932\n",
      "obtainWallItems, owner_id=-92357206retrieve 100, of total 132\n",
      "obtainWallItems, owner_id=-101271420retrieve 100, of total 5135\n",
      "obtainWallItems, owner_id=-29387592retrieve 100, of total 1750\n",
      "obtainWallItems, owner_id=-158943684retrieve 100, of total 149\n",
      "obtainWallItems, owner_id=-122422421retrieve 100, of total 6558\n",
      "obtainWallItems, owner_id=-74106120retrieve 1, of total 1\n",
      "obtainWallItems, owner_id=-50725681retrieve 100, of total 1397\n",
      "obtainWallItems, owner_id=-140465118retrieve 33, of total 33\n",
      "obtainWallItems, owner_id=-50061159retrieve 59, of total 59\n",
      "obtainWallItems, owner_id=-50774319retrieve 100, of total 1035\n",
      "obtainWallItems, owner_id=-147911279retrieve 100, of total 1766\n",
      "obtainWallItems, owner_id=-62032126retrieve 100, of total 19273\n",
      "obtainWallItems, owner_id=-30451584retrieve 3, of total 3\n",
      "obtainWallItems, owner_id=-63589724retrieve 100, of total 17591\n",
      "obtainWallItems, owner_id=-19354230retrieve 36, of total 36\n",
      "obtainWallItems, owner_id=-65314134retrieve 100, of total 854\n",
      "obtainWallItems, owner_id=-33135732retrieve 100, of total 6740\n",
      "obtainWallItems, owner_id=-79858655retrieve 1, of total 1\n",
      "obtainWallItems, owner_id=-70023397retrieve 9, of total 9\n",
      "obtainWallItems, owner_id=-43011371retrieve 100, of total 333\n",
      "obtainWallItems, owner_id=-113755164retrieve 100, of total 816\n",
      "obtainWallItems, owner_id=-66153827retrieve 100, of total 7578\n",
      "obtainWallItems, owner_id=-55500226retrieve 100, of total 23700\n",
      "obtainWallItems, owner_id=-61469977retrieve 100, of total 112\n",
      "obtainWallItems, owner_id=-150541976retrieve 5, of total 5\n",
      "obtainWallItems, owner_id=-53986544retrieve 100, of total 703\n",
      "obtainWallItems, owner_id=-152549864retrieve 100, of total 375\n",
      "obtainWallItems, owner_id=-83377401retrieve 100, of total 958\n",
      "obtainWallItems, owner_id=-144516691retrieve 100, of total 2298\n",
      "obtainWallItems, owner_id=-59683167retrieve 0, of total 0\n",
      "obtainWallItems, owner_id=-112446933retrieve 100, of total 2657\n",
      "obtainWallItems, owner_id=-154469944retrieve 55, of total 55\n",
      "obtainWallItems, owner_id=-162758293retrieve 100, of total 559\n",
      "obtainWallItems, owner_id=-21178038retrieve 60, of total 60\n",
      "obtainWallItems, owner_id=-35397045retrieve 100, of total 159\n",
      "obtainWallItems, owner_id=-2391355retrieve 100, of total 331\n",
      "obtainWallItems, owner_id=-50834921retrieve 100, of total 2705\n",
      "obtainWallItems, owner_id=-120998368retrieve 8, of total 8\n",
      "obtainWallItems, owner_id=-71306093retrieve 100, of total 3560\n",
      "obtainWallItems, owner_id=-67423173retrieve 100, of total 1103\n",
      "obtainWallItems, owner_id=-25234359retrieve 11, of total 11\n"
     ]
    }
   ],
   "source": [
    "# для каждого сообщества - получаем сообщения со стены и записваем в соотв.файл\n",
    "counter = 1 # счетчик, используем в названии файлов\n",
    "for group_id in group_ids:\n",
    "    vk_id = -1 * group_id # vk_api.wall.get по наличию знака минус - определяет, что требуется именно сообщество\n",
    "    items = obtainWallItems(api=api, owner_id=vk_id, count=COUNT_MESSAGES_PER_GROUP)\n",
    "    rawFileName = str(counter) + \"_\" + str(group_id)\n",
    "    writeJsonToFile(fileNameFunc(rawFileName), items)\n",
    "    counter = counter + 1\n",
    "    time.sleep(0.5) # соблюдаем этикет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Анализируем сохраненные данные\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пройти по всем файлам, которые с названием [N]_[id].txt\n",
    "# 1. Определяем набор полей, которые интересуют\n",
    "#   1.1 собираем набор существующих полей -> просматриваем, выбираем те, которые интересуют\n",
    "#   1.2 по выбранным полям - составляем статистику, уточняем, что именно будем выгружать\n",
    "# 2. Составляем csv-файл со всеми сообщениями, сохраняем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "#import unicodecsv as csv\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функции и константы\n",
    "\n",
    "SCRAPPED_DATA_FILE_REGEXP = re.compile(r'^([\\d]+)_([\\d]+).*$')\n",
    "\n",
    "# проанализировать массив json - какие поля встречаются\n",
    "def fieldsIn(fileContent):\n",
    "    result = []\n",
    "    for message in fileContent:\n",
    "        for key, value in message.items():\n",
    "            if(key not in result):\n",
    "                result.append(key)\n",
    "    return result\n",
    "\n",
    "# объединяем списки, оставляем уникальные элементы\n",
    "def clueFiledsFunc(acc, addFields):\n",
    "    for field in addFields:\n",
    "        if(field not in acc):\n",
    "            acc.append(field)\n",
    "    return acc\n",
    "\n",
    "# определяем, какие поля встречаются в загруженных данных\n",
    "def revealFieldNames(fileNameList):\n",
    "    fields = []\n",
    "    for fileName in scrapped_data_files:\n",
    "        with io.open(join(FOLDER_PREFIX, fileName), 'r', encoding='utf-8') as f:\n",
    "            fileContent = json.load(f)\n",
    "            fields = clueFiledsFunc(fields, fieldsIn(fileContent))\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# названия файлов со scrapped данными\n",
    "scrapped_all_files = [f for f in listdir(FOLDER_PREFIX) if isfile(join(FOLDER_PREFIX, f))]\n",
    "# только те файлы, которые про сообщения на стене сообщества\n",
    "scrapped_data_files = []\n",
    "regexp = SCRAPPED_DATA_FILE_REGEXP\n",
    "for fileName in scrapped_all_files:\n",
    "    if(regexp.search(fileName)): \n",
    "        scrapped_data_files.append(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['attachments', 'comments', 'date', 'from_id', 'id', 'is_favorite', 'likes', 'marked_as_ads', 'owner_id', 'post_source', 'post_type', 'reposts', 'text', 'views', 'is_pinned', 'signer_id', 'copy_history']\n"
     ]
    }
   ],
   "source": [
    "fields = revealFieldNames(scrapped_data_files)\n",
    "print(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# поля, которые интересуют\n",
    "actual_fields = {\n",
    "    'comments_count': 'comments.count',\n",
    "    'date':'date',\n",
    "    'is_favorite':'is_favorite',\n",
    "    'is_pinned':'is_pinned',\n",
    "    'likes_can_like':'likes.can_like',\n",
    "    'likes_can_publish':'likes.can_publish',\n",
    "    'likes_count':'likes.count',\n",
    "    'marked_as_ads':'marked_as_ads',\n",
    "    'post_source':'post_source.type',\n",
    "    'post_type':'post_type',\n",
    "    'reposts_count':'reposts.count',\n",
    "    'text':'text',\n",
    "    'views_count':'views.count'\n",
    "}\n",
    "# в обработанном виде\n",
    "csv_fields = []\n",
    "json_fields = []\n",
    "for key, value in actual_fields.items():\n",
    "    csv_fields.append(key)\n",
    "    json_fields.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем значение поля в json\n",
    "def revealFieldValue(jsonData,fieldPath):\n",
    "    none_value = ''\n",
    "    path = fieldPath.split('.')\n",
    "    data = jsonData\n",
    "    for step in path[:-1]:\n",
    "        if step in data:\n",
    "            data = data[step]\n",
    "        else:\n",
    "            return none_value\n",
    "    data = data.get(path[-1], none_value)\n",
    "    #print(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# из объекта - получаем строку для csv\n",
    "def produceLine(jsonData, fieldsList):\n",
    "    result = []\n",
    "    for field in fieldsList:\n",
    "        data = revealFieldValue(jsonData, field)\n",
    "        result.append(data)\n",
    "    return result\n",
    "\n",
    "# из файла со scrapped_data получаем строки для csv\n",
    "def produceCsvRowsForFile(fileName, fieldsList):\n",
    "    group_id = SCRAPPED_DATA_FILE_REGEXP.match(fileName).group(2)\n",
    "    result = []\n",
    "    with io.open(join(FOLDER_PREFIX, fileName), 'r', encoding='utf-8') as f:\n",
    "        fileContent = json.load(f)\n",
    "        for doc in fileContent:\n",
    "            row = [group_id] + produceLine(doc, fieldsList)\n",
    "            #row.append(group_id)\n",
    "            result.append(row)\n",
    "    return result\n",
    "            \n",
    "# для всех перечисленных файлов - записываем получаемые строки в csv (в памяти держим строки только для одного файла)\n",
    "def writeCsvLinesByFiles(csvWriter, fileNameList, fieldsList):\n",
    "    for fileName in fileNameList:\n",
    "        print('fileName: ' + fileName)\n",
    "        rows = produceCsvRowsForFile(fileName, fieldsList)\n",
    "        #print(\"***\")\n",
    "        #print(rows[1])\n",
    "        for row in rows:            \n",
    "            csvWriter.writerow(row)\n",
    "            \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comments.count', 'date', 'is_favorite', 'is_pinned', 'likes.can_like', 'likes.can_publish', 'likes.count', 'marked_as_ads', 'post_source.type', 'post_type', 'reposts.count', 'text', 'views.count']\n",
      "fileName: 10_29387592.txt\n",
      "fileName: 11_158943684.txt\n",
      "fileName: 12_122422421.txt\n",
      "fileName: 13_74106120.txt\n",
      "fileName: 14_50725681.txt\n",
      "fileName: 15_140465118.txt\n",
      "fileName: 16_50061159.txt\n",
      "fileName: 17_50774319.txt\n",
      "fileName: 18_147911279.txt\n",
      "fileName: 19_62032126.txt\n",
      "fileName: 1_46371384.txt\n",
      "fileName: 20_30451584.txt\n",
      "fileName: 21_63589724.txt\n",
      "fileName: 22_19354230.txt\n",
      "fileName: 23_65314134.txt\n",
      "fileName: 24_33135732.txt\n",
      "fileName: 25_79858655.txt\n",
      "fileName: 26_70023397.txt\n",
      "fileName: 27_43011371.txt\n",
      "fileName: 28_113755164.txt\n",
      "fileName: 29_66153827.txt\n",
      "fileName: 2_92718200.txt\n",
      "fileName: 30_55500226.txt\n",
      "fileName: 31_61469977.txt\n",
      "fileName: 32_150541976.txt\n",
      "fileName: 33_53986544.txt\n",
      "fileName: 34_152549864.txt\n",
      "fileName: 35_83377401.txt\n",
      "fileName: 36_144516691.txt\n",
      "fileName: 37_59683167.txt\n",
      "fileName: 38_112446933.txt\n",
      "fileName: 39_154469944.txt\n",
      "fileName: 3_632045.txt\n",
      "fileName: 40_162758293.txt\n",
      "fileName: 41_21178038.txt\n",
      "fileName: 42_35397045.txt\n",
      "fileName: 43_2391355.txt\n",
      "fileName: 44_50834921.txt\n",
      "fileName: 45_120998368.txt\n",
      "fileName: 46_71306093.txt\n",
      "fileName: 47_67423173.txt\n",
      "fileName: 48_25234359.txt\n",
      "fileName: 4_93604475.txt\n",
      "fileName: 5_59454515.txt\n",
      "fileName: 6_79363873.txt\n",
      "fileName: 7_51789870.txt\n",
      "fileName: 8_92357206.txt\n",
      "fileName: 9_101271420.txt\n"
     ]
    }
   ],
   "source": [
    "with open('result.csv', 'w', newline='', encoding='utf-8') as csvFile:\n",
    "    csvWriter = csv.writer(csvFile, delimiter=',')\n",
    "    csvWriter.writerow(['group_id'] + csv_fields) # 1-я строка - это названия столбцов\n",
    "    print(json_fields)\n",
    "    writeCsvLinesByFiles(csvWriter, scrapped_data_files, json_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('eggs.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',')\n",
    "    spamwriter.writerow(['Spam'] * 5 + ['Baked Beans'])\n",
    "    spamwriter.writerow(['Spam', 'Lovely Spam', 'Wonderful Spam'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
